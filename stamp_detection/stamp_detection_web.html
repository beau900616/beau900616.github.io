<!DOCTYPE html>
<html lang="zh-Hant">
<head>
  <meta charset="UTF-8" />
  <title>印章辨識 YOLOv8n</title>
  <style>
    body {
      font-family: "Noto Sans TC", Arial, sans-serif;
      margin: 20px;
      background: #fafafa;
    }
    h2 { color: #333; }
    input[type="file"] { margin: 15px 0; }
    #preview {
      display: flex;
      flex-wrap: wrap;
      gap: 20px;
    }
    canvas {
      border: 1px solid #ccc;
      border-radius: 8px;
      box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
  </style>
  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.17.1/dist/ort.min.js"></script>
  <script src="best_model_b64.js"></script>
</head>
<body>
  <h2>印章辨識 YOLOv8n (前端推論版)</h2>
  <p>請上傳 JPG 或 PNG 檔案，可多選：</p>
  <input type="file" id="imageInput" accept=".jpg,.jpeg,.png" multiple />
  <div id="preview"></div>

<script>
let session;

// === 初始化模型 ===
async function loadModel() {
  console.log("載入 YOLOv8 模型中...");
  // 將 base64 還原成二進位 ArrayBuffer
  const binary = Uint8Array.from(atob(modelBase64), c => c.charCodeAt(0));
  session = await ort.InferenceSession.create(binary.buffer, {
    executionProviders: ['wasm']
  });
  console.log("模型載入完成 ✅");
}



// === Letterbox + Tensor 轉換 ===
function letterboxImageToCanvas(img, size = 640) {
  const canvas = document.createElement("canvas");
  const ctx = canvas.getContext("2d");
  canvas.width = size;
  canvas.height = size;

  const ratio = Math.min(size / img.width, size / img.height);
  const newW = img.width * ratio;
  const newH = img.height * ratio;
  const padX = (size - newW) / 2;
  const padY = (size - newH) / 2;

  // 填灰邊
  ctx.fillStyle = "gray";
  ctx.fillRect(0, 0, size, size);

  // 繪製 letterboxed 圖片
  ctx.drawImage(img, padX, padY, newW, newH);

  return { canvas, padX, padY, ratio };
}

async function imageToTensor(img) {
  const size = 640;
  const { canvas } = letterboxImageToCanvas(img, size);
  const ctx = canvas.getContext("2d");
  const imgData = ctx.getImageData(0, 0, size, size);
  const data = imgData.data;
  const floatData = new Float32Array(size * size * 3);

  // 轉成 [1, 3, H, W] 格式並正規化
  for (let i = 0; i < data.length; i += 4) {
    const r = data[i] / 255;
    const g = data[i + 1] / 255;
    const b = data[i + 2] / 255;
    const pixelIndex = i / 4;
    const row = Math.floor(pixelIndex / size);
    const col = pixelIndex % size;
    const offset = row * size + col;
    floatData[offset] = r;
    floatData[offset + size * size] = g;
    floatData[offset + 2 * size * size] = b;
  }

  return new ort.Tensor('float32', floatData, [1, 3, size, size]);
}


// === 推論函式 ===
// ===== 工具函式 =====
function sigmoid(x) {
  return 1 / (1 + Math.exp(-x));
}

function iou(boxA, boxB) {
  // box: [x1,y1,x2,y2]
  const x1 = Math.max(boxA[0], boxB[0]);
  const y1 = Math.max(boxA[1], boxB[1]);
  const x2 = Math.min(boxA[2], boxB[2]);
  const y2 = Math.min(boxA[3], boxB[3]);
  const interW = Math.max(0, x2 - x1);
  const interH = Math.max(0, y2 - y1);
  const inter = interW * interH;
  const areaA = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1]);
  const areaB = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1]);
  const union = areaA + areaB - inter;
  return union > 0 ? inter / union : 0;
}

function nonMaxSuppression(boxes, scores, iouThreshold = 0.45, maxBoxes = 100) {
  // boxes: [[x1,y1,x2,y2], ...], scores: [s1,s2,...]
  const idxs = scores
    .map((s, i) => [s, i])
    .sort((a, b) => b[0] - a[0]) // 降序
    .map(x => x[1]);

  const keep = [];
  while (idxs.length && keep.length < maxBoxes) {
    const i = idxs.shift();
    keep.push(i);
    for (let j = idxs.length - 1; j >= 0; j--) {
      const k = idxs[j];
      if (iou(boxes[i], boxes[k]) > iouThreshold) {
        idxs.splice(j, 1); // 抑制
      }
    }
  }
  return keep; // 回傳保留的 index
}

// ===== detect with decode + NMS =====
async function detect(img, canvas) {
  if (!session) {
    console.error("模型尚未載入");
    return;
  }

  // === 1️⃣ 前處理 ===
  const size = 640;
  const { canvas: letterCanvas, ratio, padX, padY } = letterboxImageToCanvas(img, size);
  const tensor = await imageToTensor(img);

  // === 2️⃣ 推論 ===
  const output = await session.run({ images: tensor });
  const key = Object.keys(output)[0];
  const out = output[key];
  const data = out.data;
  const shape = out.dims; // [1,84,8400]

  const numFeat = shape[1];
  const numPred = shape[2];
  const numClasses = numFeat - 4;

  const boxes = [], scores = [], classIds = [];

  // === 3️⃣ 解碼 ===
  for (let i = 0; i < numPred; i++) {
    const cx = data[i];
    const cy = data[numPred + i];
    const w  = data[2 * numPred + i];
    const h  = data[3 * numPred + i];

    const x1 = cx - w / 2;
    const y1 = cy - h / 2;
    const x2 = cx + w / 2;
    const y2 = cy + h / 2;

    let bestClass = -1;
    let bestScore = 0;
    for (let c = 0; c < numClasses; c++) {
      const raw = data[(4 + c) * numPred + i];
      const prob = sigmoid(raw); // 若已Sigmoid可略
      if (prob > bestScore) {
        bestScore = prob;
        bestClass = c;
      }
    }

    if (bestScore > 0.25) {
      // 還原至原圖座標
      const x1r = (x1 - padX) / ratio;
      const y1r = (y1 - padY) / ratio;
      const x2r = (x2 - padX) / ratio;
      const y2r = (y2 - padY) / ratio;

      boxes.push([x1r, y1r, x2r, y2r]);
      scores.push(bestScore);
      classIds.push(bestClass);
    }
  }

  // === 4️⃣ NMS ===
  const keepIdx = nonMaxSuppression(boxes, scores, 0.45, 50);

  // === 5️⃣ 繪製 ===
  const ctx = canvas.getContext("2d");
  const W = canvas.width, H = canvas.height;
  ctx.clearRect(0, 0, W, H);
  ctx.drawImage(img, 0, 0, W, H);
  ctx.strokeStyle = "red";
  ctx.fillStyle = "red";
  ctx.lineWidth = 2;
  ctx.font = "14px sans-serif";

  for (const idx of keepIdx) {
    const [x1, y1, x2, y2] = boxes[idx];
    const score = scores[idx];
    const width = x2 - x1;
    const height = y2 - y1;
    ctx.beginPath();
    ctx.rect(x1, y1, width, height);
    ctx.stroke();
    ctx.fillText(`Seal ${(score * 100).toFixed(1)}%`, x1, Math.max(12, y1 - 6));
  }

  console.log("檢測結果 (保留數):", keepIdx.length);
}



// === 上傳圖片處理 ===
document.getElementById("imageInput").addEventListener("change", async e => {
  const files = [...e.target.files];
  const preview = document.getElementById("preview");
  preview.innerHTML = "";

  for (const file of files) {
    if (!file.type.startsWith("image/")) continue;
    const img = new Image();
    img.src = URL.createObjectURL(file);
    await img.decode();

    const canvas = document.createElement("canvas");
    canvas.width = 640;
    canvas.height = 640;
    preview.appendChild(canvas);

    await detect(img, canvas);
  }
});

loadModel();

</script>
</body>
</html>
